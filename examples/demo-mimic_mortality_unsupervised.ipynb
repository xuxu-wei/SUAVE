{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d2c20b",
   "metadata": {},
   "source": [
    "# MIMIC mortality (unsupervised)\n",
    "\n",
    "This notebook reproduces the unsupervised SUAVE mortality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ae3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Dict, List, Mapping, Optional, Tuple\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "EXAMPLES_DIR = Path().resolve()\n",
    "if not EXAMPLES_DIR.exists():\n",
    "    raise RuntimeError(\"Run this notebook from the repository root so 'examples' is available.\")\n",
    "if str(EXAMPLES_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(EXAMPLES_DIR))\n",
    "\n",
    "from mimic_mortality_utils import (\n",
    "    RANDOM_STATE,\n",
    "    TARGET_COLUMNS,\n",
    "    CALIBRATION_SIZE,\n",
    "    VALIDATION_SIZE,\n",
    "    Schema,\n",
    "    define_schema,\n",
    "    compute_auc,\n",
    "    format_float,\n",
    "    load_dataset,\n",
    "    prepare_features,\n",
    "    schema_markdown_table,\n",
    "    split_train_validation_calibration,\n",
    "    to_numeric_frame,\n",
    ")\n",
    "\n",
    "from suave import SUAVE\n",
    "from suave.evaluate import (\n",
    "    evaluate_tstr,\n",
    "    evaluate_trtr,\n",
    "    simple_membership_inference,\n",
    "    kolmogorov_smirnov_statistic,\n",
    "    mutual_information_feature,\n",
    "    rbf_mmd,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5992f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[schema] Column 'age' flagged for review: Integer feature near categorical threshold.\n",
      "[schema] Column 'PaO2/FiO2' flagged for review: Positive skew close to threshold.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Column | Type | n_classes | y_dim |\n",
       "| --- | --- | --- | --- |\n",
       "| age | real |  |  |\n",
       "| sex | cat | 2 |  |\n",
       "| BMI | real |  |  |\n",
       "| temperature | real |  |  |\n",
       "| heart_rate | real |  |  |\n",
       "| respir_rate | real |  |  |\n",
       "| SBP | real |  |  |\n",
       "| DBP | real |  |  |\n",
       "| MAP | real |  |  |\n",
       "| SOFA_cns | ordinal | 5 |  |\n",
       "| CRRT | cat | 2 |  |\n",
       "| Respiratory_Support | ordinal | 5 |  |\n",
       "| WBC | pos |  |  |\n",
       "| Hb | real |  |  |\n",
       "| NE% | real |  |  |\n",
       "| LYM% | real |  |  |\n",
       "| PLT | pos |  |  |\n",
       "| ALT | pos |  |  |\n",
       "| AST | pos |  |  |\n",
       "| STB | pos |  |  |\n",
       "| BUN | pos |  |  |\n",
       "| Scr | pos |  |  |\n",
       "| Glu | pos |  |  |\n",
       "| K+ | real |  |  |\n",
       "| Na+ | real |  |  |\n",
       "| Fg | pos |  |  |\n",
       "| PT | pos |  |  |\n",
       "| APTT | pos |  |  |\n",
       "| PH | real |  |  |\n",
       "| PaO2/FiO2 | pos |  |  |\n",
       "| PaCO2 | pos |  |  |\n",
       "| HCO3- | real |  |  |\n",
       "| Lac | pos |  |  |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_DIR = (EXAMPLES_DIR / \"data\" / \"sepsis_mortality_dataset\").resolve()\n",
    "OUTPUT_DIR = EXAMPLES_DIR / \"analysis_outputs_unsupervised\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "train_df = load_dataset(DATA_DIR / \"mimic-mortality-train.tsv\")\n",
    "test_df = load_dataset(DATA_DIR / \"mimic-mortality-test.tsv\")\n",
    "external_df = load_dataset(DATA_DIR / \"eicu-mortality-external_val.tsv\")\n",
    "\n",
    "FEATURE_COLUMNS = [column for column in train_df.columns if column not in [*TARGET_COLUMNS, 'PaO2']]\n",
    "schema = define_schema(train_df, FEATURE_COLUMNS)\n",
    "\n",
    "# manual schema correction\n",
    "schema.update({'BMI':{'type': 'real'}})\n",
    "schema.update({'Respiratory_Support':{'type': 'ordinal', 'n_classes': 5}})\n",
    "schema.update({'LYM%':{'type': 'real'}})\n",
    "\n",
    "schema_table = schema_markdown_table(schema)\n",
    "display(Markdown(schema_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e25b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_latent_classifier() -> Pipeline:\n",
    "    \"\"\"Return the logistic regression pipeline used on latent representations.\"\"\"\n",
    "\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", LogisticRegression(max_iter=1000)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def make_logistic_pipeline() -> Pipeline:\n",
    "    \"\"\"Factory for the baseline classifier used in TSTR/TRTR.\"\"\"\n",
    "\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", LogisticRegression(max_iter=200)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe95972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unsupervised model for in_hospital_mortality…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f7202319dc4db9b61b15d6a826f0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unsupervised model for 28d_mortality…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6689256b396149438e907d84e199a124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for TSTR/TRTR comparisons…\n",
      "Analysis complete.\n",
      "Metric table saved to E:\\BaiduNetdiskWorkspace\\Jupyter\\my_repos\\SUAVE\\examples\\analysis_outputs_unsupervised\\evaluation_metrics_unsupervised.csv\n",
      "Membership inference results saved to E:\\BaiduNetdiskWorkspace\\Jupyter\\my_repos\\SUAVE\\examples\\analysis_outputs_unsupervised\\membership_inference_unsupervised.csv\n",
      "TSTR/TRTR comparison saved to E:\\BaiduNetdiskWorkspace\\Jupyter\\my_repos\\SUAVE\\examples\\analysis_outputs_unsupervised\\tstr_trtr_comparison_unsupervised.csv\n",
      "Distribution metrics saved to E:\\BaiduNetdiskWorkspace\\Jupyter\\my_repos\\SUAVE\\examples\\analysis_outputs_unsupervised\\distribution_shift_metrics_unsupervised.csv\n",
      "Summary written to E:\\BaiduNetdiskWorkspace\\Jupyter\\my_repos\\SUAVE\\examples\\analysis_outputs_unsupervised\\summary_unsupervised.md\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics_records: List[Dict[str, object]] = []\n",
    "membership_records: List[Dict[str, object]] = []\n",
    "\n",
    "latent_models: Dict[str, Pipeline] = {}\n",
    "suave_models: Dict[str, SUAVE] = {}\n",
    "\n",
    "tstr_results: Optional[pd.DataFrame] = None\n",
    "tstr_path: Optional[Path] = None\n",
    "distribution_df: Optional[pd.DataFrame] = None\n",
    "distribution_path: Optional[Path] = None\n",
    "\n",
    "for target in TARGET_COLUMNS:\n",
    "    if target not in train_df.columns:\n",
    "        continue\n",
    "    print(f\"Training unsupervised model for {target}…\")\n",
    "    X_full = prepare_features(train_df, FEATURE_COLUMNS)\n",
    "    y_full = train_df[target]\n",
    "\n",
    "    (\n",
    "        X_train_model,\n",
    "        X_validation,\n",
    "        y_train_model,\n",
    "        y_validation,\n",
    "    ) = train_test_split(\n",
    "        X_full,\n",
    "        y_full,\n",
    "        test_size=VALIDATION_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_full\n",
    "    )\n",
    "\n",
    "    hidden_dimension_options: Dict[str, Tuple[int, int]] = {\n",
    "        \"compact\": (128, 64),\n",
    "        \"balanced\": (256, 128),\n",
    "        \"widened\": (384, 192),\n",
    "        \"extended\": (512, 256),\n",
    "    }\n",
    "    model = SUAVE(\n",
    "        schema=schema,\n",
    "        behaviour=\"unsupervised\",\n",
    "        latent_dim=32,\n",
    "        hidden_dims=(384, 192),\n",
    "        dropout=0.01,\n",
    "        learning_rate=0.0003,\n",
    "        batch_size=1024,\n",
    "        beta=1.0,\n",
    "        n_components=7,\n",
    "        tau_start=4,\n",
    "        tau_min=0.04,\n",
    "        tau_decay=0.001,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train_model,\n",
    "        warmup_epochs=50,\n",
    "        kl_warmup_epochs=6,\n",
    "        plot_monitor=True\n",
    "    )\n",
    "    suave_models[target] = model\n",
    "\n",
    "    latent_classifier = make_latent_classifier()\n",
    "    train_latents = model.encode(X_train_model)\n",
    "\n",
    "    evaluation_datasets: Dict[str, Tuple[pd.DataFrame, pd.Series]] = {\n",
    "        \"Train\": (X_train_model, y_train_model),\n",
    "        \"Validation\": (X_validation, y_validation),\n",
    "        \"MIMIC test\": (\n",
    "            prepare_features(test_df, FEATURE_COLUMNS),\n",
    "            test_df[target],\n",
    "        ),\n",
    "    }\n",
    "    if target in external_df.columns:\n",
    "        evaluation_datasets[\"eICU external\"] = (\n",
    "            prepare_features(external_df, FEATURE_COLUMNS),\n",
    "            external_df[target],\n",
    "        )\n",
    "\n",
    "    latent_classifier.fit(train_latents, np.asarray(y_train_model))\n",
    "    latent_models[target] = latent_classifier\n",
    "\n",
    "    for dataset_name, (features, labels) in evaluation_datasets.items():\n",
    "        latents = model.encode(features)\n",
    "        probs = latent_classifier.predict_proba(latents)\n",
    "        auc = compute_auc(probs, labels)\n",
    "        metrics_records.append(\n",
    "            {\n",
    "                \"target\": target,\n",
    "                \"dataset\": dataset_name,\n",
    "                \"auc\": auc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    train_probs = latent_classifier.predict_proba(train_latents)\n",
    "    test_latents = model.encode(evaluation_datasets[\"MIMIC test\"][0])\n",
    "    test_probs = latent_classifier.predict_proba(test_latents)\n",
    "    membership = simple_membership_inference(\n",
    "        train_probs,\n",
    "        np.asarray(y_train_model),\n",
    "        test_probs,\n",
    "        np.asarray(evaluation_datasets[\"MIMIC test\"][1]),\n",
    "    )\n",
    "    membership_records.append({\"target\": target, **membership})\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_records)\n",
    "metrics_path = OUTPUT_DIR / \"evaluation_metrics_unsupervised.csv\"\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "membership_df = pd.DataFrame(membership_records)\n",
    "membership_path = OUTPUT_DIR / \"membership_inference_unsupervised.csv\"\n",
    "membership_df.to_csv(membership_path, index=False)\n",
    "\n",
    "primary_target = \"in_hospital_mortality\"\n",
    "if primary_target in suave_models and primary_target in latent_models:\n",
    "    print(\"Generating synthetic data for TSTR/TRTR comparisons…\")\n",
    "    model = suave_models[primary_target]\n",
    "    latent_classifier = latent_models[primary_target]\n",
    "\n",
    "    X_train_full = prepare_features(train_df, FEATURE_COLUMNS)\n",
    "    y_train_full = train_df[primary_target]\n",
    "    numeric_train = to_numeric_frame(X_train_full)\n",
    "    train_means = numeric_train.mean(axis=0)\n",
    "    train_means = train_means.fillna(0.0)\n",
    "    numeric_train = numeric_train.fillna(train_means)\n",
    "\n",
    "    synthetic_features = model.sample(len(X_train_full))\n",
    "    synthetic_features = synthetic_features[FEATURE_COLUMNS]\n",
    "    numeric_synthetic = to_numeric_frame(synthetic_features)\n",
    "    numeric_synthetic = numeric_synthetic.fillna(train_means)\n",
    "\n",
    "    synthetic_latents = model.encode(synthetic_features)\n",
    "    synthetic_probs = latent_classifier.predict_proba(synthetic_latents)[:, 1]\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    synthetic_labels = rng.binomial(1, synthetic_probs)\n",
    "\n",
    "    numeric_test = to_numeric_frame(prepare_features(test_df, FEATURE_COLUMNS))\n",
    "    numeric_test = numeric_test.fillna(train_means)\n",
    "    y_test = test_df[primary_target]\n",
    "\n",
    "    tstr_metrics = evaluate_tstr(\n",
    "        (numeric_synthetic.to_numpy(), synthetic_labels),\n",
    "        (numeric_test.to_numpy(), y_test.to_numpy()),\n",
    "        make_logistic_pipeline,\n",
    "    )\n",
    "    trtr_metrics = evaluate_trtr(\n",
    "        (numeric_train.to_numpy(), y_train_full.to_numpy()),\n",
    "        (numeric_test.to_numpy(), y_test.to_numpy()),\n",
    "        make_logistic_pipeline,\n",
    "    )\n",
    "    tstr_results = pd.DataFrame(\n",
    "        [\n",
    "            {\"setting\": \"TSTR\", **tstr_metrics},\n",
    "            {\"setting\": \"TRTR\", **trtr_metrics},\n",
    "        ]\n",
    "    )\n",
    "    tstr_path = OUTPUT_DIR / \"tstr_trtr_comparison_unsupervised.csv\"\n",
    "    tstr_results.to_csv(tstr_path, index=False)\n",
    "\n",
    "    distribution_rows: List[Dict[str, object]] = []\n",
    "    for column in FEATURE_COLUMNS:\n",
    "        real_values = numeric_train[column].to_numpy()\n",
    "        synthetic_values = numeric_synthetic[column].to_numpy()\n",
    "        distribution_rows.append(\n",
    "            {\n",
    "                \"feature\": column,\n",
    "                \"ks\": kolmogorov_smirnov_statistic(real_values, synthetic_values),\n",
    "                \"mmd\": rbf_mmd(\n",
    "                    real_values, synthetic_values, random_state=RANDOM_STATE\n",
    "                ),\n",
    "                \"mutual_information\": mutual_information_feature(\n",
    "                    real_values, synthetic_values\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "    distribution_df = pd.DataFrame(distribution_rows)\n",
    "    distribution_path = OUTPUT_DIR / \"distribution_shift_metrics_unsupervised.csv\"\n",
    "    distribution_df.to_csv(distribution_path, index=False)\n",
    "else:\n",
    "    print(\"Primary target model not available; skipping TSTR/TRTR and distribution analysis.\")\n",
    "\n",
    "\n",
    "summary_lines: List[str] = [\n",
    "    \"# Unsupervised mortality modelling report\",\n",
    "    \"\",\n",
    "    \"## Schema\",\n",
    "    schema_table,\n",
    "    \"\",\n",
    "    \"## Model selection and performance\",\n",
    "]\n",
    "\n",
    "\n",
    "if tstr_results is not None:\n",
    "    summary_lines.append(\"## TSTR vs TRTR\")\n",
    "    summary_lines.append(\"| Setting | Accuracy | AUC | AUPRC | Brier | ECE |\")\n",
    "    summary_lines.append(\"| --- | --- | --- | --- | --- | --- |\")\n",
    "    for _, row in tstr_results.iterrows():\n",
    "        summary_lines.append(\n",
    "            \"| {setting} | {acc:.3f} | {auc:.3f} | {auprc:.3f} | {brier:.3f} | {ece:.3f} |\".format(\n",
    "                setting=row[\"setting\"],\n",
    "                acc=row.get(\"accuracy\", np.nan),\n",
    "                auc=row.get(\"auroc\", np.nan),\n",
    "                auprc=row.get(\"auprc\", np.nan),\n",
    "                brier=row.get(\"brier\", np.nan),\n",
    "                ece=row.get(\"ece\", np.nan),\n",
    "            )\n",
    "        )\n",
    "    summary_lines.append(\"\")\n",
    "\n",
    "summary_lines.append(\"## Distribution shift and privacy\")\n",
    "if distribution_df is not None and distribution_path is not None:\n",
    "    distribution_top = distribution_df.sort_values(\"ks\", ascending=False).head(10)\n",
    "    summary_lines.append(\"Top 10 features by KS statistic:\")\n",
    "    summary_lines.append(\"| Feature | KS | MMD | Mutual information |\")\n",
    "    summary_lines.append(\"| --- | --- | --- | --- |\")\n",
    "    for _, row in distribution_top.iterrows():\n",
    "        summary_lines.append(\n",
    "            \"| {feature} | {ks:.3f} | {mmd:.3f} | {mi:.3f} |\".format(\n",
    "                feature=row[\"feature\"],\n",
    "                ks=row.get(\"ks\", np.nan),\n",
    "                mmd=row.get(\"mmd\", np.nan),\n",
    "                mi=row.get(\"mutual_information\", np.nan),\n",
    "            )\n",
    "        )\n",
    "    summary_lines.append(\n",
    "        f\"Full distribution metrics: {distribution_path.relative_to(OUTPUT_DIR)}\"\n",
    "    )\n",
    "else:\n",
    "    summary_lines.append(\"Distribution metrics were not computed.\")\n",
    "\n",
    "if not membership_records:\n",
    "    summary_lines.append(\"No membership inference metrics were recorded.\")\n",
    "else:\n",
    "    summary_lines.append(\"Membership inference results:\")\n",
    "    summary_lines.append(\n",
    "        \"| Target | attack_auc | attack_accuracy | attack_threshold |\"\n",
    "    )\n",
    "    summary_lines.append(\"| --- | --- | --- | --- |\")\n",
    "    for _, row in pd.DataFrame(membership_records).iterrows():\n",
    "        summary_lines.append(\n",
    "            \"| {target} | {auc:.3f} | {accuracy:.3f} | {threshold:.3f} |\".format(\n",
    "                target=row[\"target\"],\n",
    "                auc=row.get(\"attack_auc\", np.nan),\n",
    "                accuracy=row.get(\"attack_best_accuracy\", np.nan),\n",
    "                threshold=row.get(\"attack_best_threshold\", np.nan),\n",
    "            )\n",
    "        )\n",
    "    summary_lines.append(\n",
    "        f\"Membership metrics saved to: {membership_path.relative_to(OUTPUT_DIR)}\"\n",
    "    )\n",
    "\n",
    "summary_path = OUTPUT_DIR / \"summary_unsupervised.md\"\n",
    "summary_path.write_text(\"\\n\".join(summary_lines), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Analysis complete.\")\n",
    "print(f\"Metric table saved to {metrics_path}\")\n",
    "print(f\"Membership inference results saved to {membership_path}\")\n",
    "if tstr_path is not None and distribution_path is not None:\n",
    "    print(f\"TSTR/TRTR comparison saved to {tstr_path}\")\n",
    "    print(f\"Distribution metrics saved to {distribution_path}\")\n",
    "print(f\"Summary written to {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dba732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}